//! Artifact generators: `llms.txt`, `llms-full.txt`, `SKILL.md`, `rules.md`, `style.md`, `do_dont.md`.
//!
//! Each generator accepts pre-computed data (enrichment results, TOC, page content)
//! and produces deterministic output. Generators never call an LLM directly.

use std::collections::HashMap;
use std::fmt::Write;

use contextbuilder_shared::{Toc, TocEntry};

/// Standard provenance comment inserted at the top of every generated artifact.
fn provenance_comment(source_url: &str, tool_version: &str) -> String {
    format!("<!-- Generated by ContextBuilder v{tool_version} from {source_url} -->")
}

// ---------------------------------------------------------------------------
// Artifact names
// ---------------------------------------------------------------------------

/// Constant artifact file names matching the TypeScript `ARTIFACT_NAMES`.
pub const ARTIFACT_NAMES: [&str; 6] = [
    "llms.txt",
    "llms-full.txt",
    "SKILL.md",
    "rules.md",
    "style.md",
    "do_dont.md",
];

// ---------------------------------------------------------------------------
// llms.txt
// ---------------------------------------------------------------------------

/// A page entry for the `llms.txt` generator.
#[derive(Debug, Clone)]
pub struct LlmsEntry {
    /// Display title.
    pub title: String,
    /// Source URL.
    pub url: String,
    /// One-line description from enrichment.
    pub description: String,
}

/// Generate `llms.txt` following the [llmstxt.org](https://llmstxt.org) format.
///
/// Format:
/// ```text
/// # <name>
///
/// > <summary>
///
/// ## Section
///
/// - [Title](url): description
/// ```
pub fn generate_llms_txt(
    name: &str,
    summary: &str,
    toc: &Toc,
    descriptions: &HashMap<String, String>,
    source_url: &str,
    tool_version: &str,
) -> String {
    let mut out = String::new();
    let _ = writeln!(out, "{}", provenance_comment(source_url, tool_version));
    let _ = writeln!(out);
    let _ = writeln!(out, "# {name}");
    let _ = writeln!(out);
    let _ = writeln!(out, "> {summary}");
    let _ = writeln!(out);

    write_llms_sections(&mut out, &toc.sections, descriptions, 2);

    out
}

/// Recursively write TOC sections as Markdown headings with link entries.
fn write_llms_sections(
    out: &mut String,
    entries: &[TocEntry],
    descriptions: &HashMap<String, String>,
    heading_level: usize,
) {
    for entry in entries {
        if entry.children.is_empty() {
            // Leaf entry: write as a link line
            let desc = descriptions
                .get(&entry.path)
                .map(String::as_str)
                .unwrap_or("Documentation page");
            let url = entry
                .source_url
                .as_deref()
                .unwrap_or(&entry.path);
            let _ = writeln!(out, "- [{}]({}): {}", entry.title, url, desc);
        } else {
            // Section heading
            let hashes = "#".repeat(heading_level.min(6));
            let _ = writeln!(out);
            let _ = writeln!(out, "{hashes} {}", entry.title);
            let _ = writeln!(out);

            // If this section node also has a source_url, include it as an entry
            if entry.source_url.is_some() {
                let desc = descriptions
                    .get(&entry.path)
                    .map(String::as_str)
                    .unwrap_or("Section overview");
                let url = entry.source_url.as_deref().unwrap();
                let _ = writeln!(out, "- [{}]({}): {}", entry.title, url, desc);
            }

            write_llms_sections(out, &entry.children, descriptions, heading_level + 1);
        }
    }
}

// ---------------------------------------------------------------------------
// llms-full.txt
// ---------------------------------------------------------------------------

/// A page with full content for the `llms-full.txt` generator.
#[derive(Debug, Clone)]
pub struct FullPage {
    /// Display title.
    pub title: String,
    /// Source URL.
    pub url: String,
    /// Full Markdown content.
    pub content: String,
}

/// Generate `llms-full.txt`: a single concatenated Markdown file with all page content.
///
/// Includes a table of contents at the top linking to H2 section anchors.
pub fn generate_llms_full_txt(
    name: &str,
    pages: &[FullPage],
    source_url: &str,
    tool_version: &str,
) -> String {
    let mut out = String::new();
    let _ = writeln!(out, "{}", provenance_comment(source_url, tool_version));
    let _ = writeln!(out);
    let _ = writeln!(out, "# {name} — Full Documentation");
    let _ = writeln!(out);

    // Table of contents
    let _ = writeln!(out, "## Table of Contents");
    let _ = writeln!(out);
    for page in pages {
        let anchor = title_to_anchor(&page.title);
        let _ = writeln!(out, "- [{}](#{})", page.title, anchor);
    }
    let _ = writeln!(out);

    // Page sections
    for page in pages {
        let _ = writeln!(out, "---");
        let _ = writeln!(out);
        let _ = writeln!(out, "## {}", page.title);
        let _ = writeln!(out);
        let _ = writeln!(out, "<!-- source: {} -->", page.url);
        let _ = writeln!(out);
        let _ = writeln!(out, "{}", page.content.trim());
        let _ = writeln!(out);
    }

    out
}

/// Convert a title to a GitHub-flavored Markdown anchor slug.
fn title_to_anchor(title: &str) -> String {
    title
        .to_lowercase()
        .chars()
        .map(|c| {
            if c.is_alphanumeric() {
                c
            } else if c == ' ' || c == '-' {
                '-'
            } else {
                '_'
            }
        })
        .collect::<String>()
}

// ---------------------------------------------------------------------------
// SKILL.md
// ---------------------------------------------------------------------------

/// Generate `SKILL.md` following the Agent Skills specification.
///
/// If enrichment provided content, it is used as the body.
/// Otherwise, a minimal skeleton is generated from the KB metadata.
pub fn generate_skill_md(
    name: &str,
    source_url: &str,
    description: &str,
    enrichment_content: Option<&str>,
    tool_version: &str,
) -> String {
    let mut out = String::new();
    let _ = writeln!(out, "{}", provenance_comment(source_url, tool_version));
    let _ = writeln!(out);

    // YAML frontmatter
    let _ = writeln!(out, "---");
    let _ = writeln!(out, "name: {name}");
    let _ = writeln!(out, "version: 1.0.0");
    let _ = writeln!(out, "description: \"{description}\"");
    let _ = writeln!(out, "source: {source_url}");
    let _ = writeln!(out, "---");
    let _ = writeln!(out);

    if let Some(content) = enrichment_content {
        let _ = writeln!(out, "{}", content.trim());
    } else {
        // Fallback skeleton
        let _ = writeln!(out, "# {name}");
        let _ = writeln!(out);
        let _ = writeln!(out, "{description}");
        let _ = writeln!(out);
        let _ = writeln!(out, "## Overview");
        let _ = writeln!(out);
        let _ = writeln!(out, "See the documentation at {source_url}");
    }

    let _ = writeln!(out);
    out
}

// ---------------------------------------------------------------------------
// rules.md
// ---------------------------------------------------------------------------

/// Generate `rules.md` from enrichment content.
pub fn generate_rules(
    name: &str,
    source_url: &str,
    enrichment_content: Option<&str>,
    tool_version: &str,
) -> String {
    generate_passthrough_artifact(
        "rules.md",
        &format!("Coding Rules — {name}"),
        source_url,
        enrichment_content,
        "No specific coding rules were extracted from this documentation.",
        tool_version,
    )
}

// ---------------------------------------------------------------------------
// style.md
// ---------------------------------------------------------------------------

/// Generate `style.md` from enrichment content.
pub fn generate_style(
    name: &str,
    source_url: &str,
    enrichment_content: Option<&str>,
    tool_version: &str,
) -> String {
    generate_passthrough_artifact(
        "style.md",
        &format!("Style Guide — {name}"),
        source_url,
        enrichment_content,
        "No specific style guidelines were extracted from this documentation.",
        tool_version,
    )
}

// ---------------------------------------------------------------------------
// do_dont.md
// ---------------------------------------------------------------------------

/// Generate `do_dont.md` from enrichment content.
pub fn generate_do_dont(
    name: &str,
    source_url: &str,
    enrichment_content: Option<&str>,
    tool_version: &str,
) -> String {
    generate_passthrough_artifact(
        "do_dont.md",
        &format!("Do's and Don'ts — {name}"),
        source_url,
        enrichment_content,
        "No specific do's and don'ts were extracted from this documentation.",
        tool_version,
    )
}

// ---------------------------------------------------------------------------
// Helpers
// ---------------------------------------------------------------------------

/// Generate a "pass-through" artifact that wraps enrichment content with
/// a heading and provenance comment, or falls back to a placeholder.
fn generate_passthrough_artifact(
    _filename: &str,
    heading: &str,
    source_url: &str,
    enrichment_content: Option<&str>,
    fallback: &str,
    tool_version: &str,
) -> String {
    let mut out = String::new();
    let _ = writeln!(out, "{}", provenance_comment(source_url, tool_version));
    let _ = writeln!(out);
    let _ = writeln!(out, "# {heading}");
    let _ = writeln!(out);

    if let Some(content) = enrichment_content {
        let _ = writeln!(out, "{}", content.trim());
    } else {
        let _ = writeln!(out, "{fallback}");
    }

    let _ = writeln!(out);
    out
}

/// All artifact metadata (file name + SHA-256 hash) for manifest population.
#[derive(Debug, Clone, serde::Serialize)]
pub struct ArtifactEntry {
    pub filename: String,
    pub sha256: String,
    pub size_bytes: usize,
}

/// Compute SHA-256 hash of artifact content.
pub fn sha256_hex(content: &str) -> String {
    use sha2::{Digest, Sha256};
    let mut hasher = Sha256::new();
    hasher.update(content.as_bytes());
    format!("{:x}", hasher.finalize())
}

// ---------------------------------------------------------------------------
// Tests
// ---------------------------------------------------------------------------

#[cfg(test)]
mod tests {
    use super::*;

    fn sample_toc() -> Toc {
        Toc {
            sections: vec![
                TocEntry {
                    title: "Getting Started".into(),
                    path: "getting-started".into(),
                    source_url: Some("https://example.com/getting-started".into()),
                    summary: None,
                    children: vec![],
                },
                TocEntry {
                    title: "API Reference".into(),
                    path: "api".into(),
                    source_url: Some("https://example.com/api".into()),
                    summary: None,
                    children: vec![
                        TocEntry {
                            title: "Authentication".into(),
                            path: "api/auth".into(),
                            source_url: Some("https://example.com/api/auth".into()),
                            summary: None,
                            children: vec![],
                        },
                        TocEntry {
                            title: "Endpoints".into(),
                            path: "api/endpoints".into(),
                            source_url: Some("https://example.com/api/endpoints".into()),
                            summary: None,
                            children: vec![],
                        },
                    ],
                },
            ],
        }
    }

    fn sample_descriptions() -> HashMap<String, String> {
        let mut m = HashMap::new();
        m.insert("getting-started".into(), "Quick start guide".into());
        m.insert("api".into(), "Full API reference".into());
        m.insert("api/auth".into(), "Authentication methods".into());
        m.insert("api/endpoints".into(), "Available REST endpoints".into());
        m
    }

    // llms.txt tests --------------------------------------------------

    #[test]
    fn llms_txt_contains_provenance() {
        let toc = Toc { sections: vec![] };
        let out = generate_llms_txt("MyLib", "A library", &toc, &HashMap::new(), "https://example.com", "0.1.0");
        assert!(out.contains("<!-- Generated by ContextBuilder v0.1.0 from https://example.com -->"));
    }

    #[test]
    fn llms_txt_has_title_and_summary() {
        let toc = Toc { sections: vec![] };
        let out = generate_llms_txt("MyLib", "A great library", &toc, &HashMap::new(), "https://example.com", "0.1.0");
        assert!(out.contains("# MyLib"));
        assert!(out.contains("> A great library"));
    }

    #[test]
    fn llms_txt_generates_entries_from_toc() {
        let toc = sample_toc();
        let descs = sample_descriptions();
        let out = generate_llms_txt("MyLib", "Summary", &toc, &descs, "https://example.com", "0.1.0");

        assert!(out.contains("- [Getting Started](https://example.com/getting-started): Quick start guide"));
        assert!(out.contains("## API Reference"));
        assert!(out.contains("- [Authentication](https://example.com/api/auth): Authentication methods"));
        assert!(out.contains("- [Endpoints](https://example.com/api/endpoints): Available REST endpoints"));
    }

    #[test]
    fn llms_txt_fallback_description() {
        let toc = Toc {
            sections: vec![TocEntry {
                title: "Unknown".into(),
                path: "unknown".into(),
                source_url: Some("https://example.com/unknown".into()),
                summary: None,
                children: vec![],
            }],
        };
        let out = generate_llms_txt("Lib", "Sum", &toc, &HashMap::new(), "https://example.com", "0.1.0");
        assert!(out.contains("Documentation page"));
    }

    // llms-full.txt tests -------------------------------------------------

    #[test]
    fn llms_full_txt_contains_provenance() {
        let out = generate_llms_full_txt("MyLib", &[], "https://example.com", "0.1.0");
        assert!(out.contains("<!-- Generated by ContextBuilder v0.1.0"));
    }

    #[test]
    fn llms_full_txt_has_toc_and_pages() {
        let pages = vec![
            FullPage {
                title: "Intro".into(),
                url: "https://example.com/intro".into(),
                content: "Welcome to the library.".into(),
            },
            FullPage {
                title: "Setup".into(),
                url: "https://example.com/setup".into(),
                content: "Run npm install.".into(),
            },
        ];

        let out = generate_llms_full_txt("MyLib", &pages, "https://example.com", "0.1.0");

        // Table of contents
        assert!(out.contains("## Table of Contents"));
        assert!(out.contains("- [Intro](#intro)"));
        assert!(out.contains("- [Setup](#setup)"));

        // Page sections
        assert!(out.contains("## Intro"));
        assert!(out.contains("<!-- source: https://example.com/intro -->"));
        assert!(out.contains("Welcome to the library."));
        assert!(out.contains("## Setup"));
        assert!(out.contains("Run npm install."));
    }

    #[test]
    fn llms_full_txt_separators_between_pages() {
        let pages = vec![
            FullPage { title: "A".into(), url: "u1".into(), content: "c1".into() },
            FullPage { title: "B".into(), url: "u2".into(), content: "c2".into() },
        ];
        let out = generate_llms_full_txt("Lib", &pages, "u", "0.1.0");
        let separator_count = out.matches("---").count();
        assert_eq!(separator_count, 2, "each page should have a separator");
    }

    // SKILL.md tests -------------------------------------------------------

    #[test]
    fn skill_md_has_frontmatter() {
        let out = generate_skill_md("MyLib", "https://example.com", "A library", None, "0.1.0");
        assert!(out.contains("---\nname: MyLib"));
        assert!(out.contains("version: 1.0.0"));
        assert!(out.contains("description: \"A library\""));
        assert!(out.contains("source: https://example.com"));
    }

    #[test]
    fn skill_md_uses_enrichment_content() {
        let out = generate_skill_md("Lib", "u", "d", Some("## Custom Content\n\nRich skill."), "0.1.0");
        assert!(out.contains("## Custom Content"));
        assert!(out.contains("Rich skill."));
    }

    #[test]
    fn skill_md_fallback_without_enrichment() {
        let out = generate_skill_md("Lib", "https://x.com", "desc", None, "0.1.0");
        assert!(out.contains("# Lib"));
        assert!(out.contains("## Overview"));
        assert!(out.contains("See the documentation at https://x.com"));
    }

    // rules.md tests -------------------------------------------------------

    #[test]
    fn rules_with_enrichment() {
        let out = generate_rules("Lib", "u", Some("Rule 1: use strict mode"), "0.1.0");
        assert!(out.contains("# Coding Rules — Lib"));
        assert!(out.contains("Rule 1: use strict mode"));
    }

    #[test]
    fn rules_fallback() {
        let out = generate_rules("Lib", "u", None, "0.1.0");
        assert!(out.contains("No specific coding rules"));
    }

    // style.md tests --------------------------------------------------------

    #[test]
    fn style_with_enrichment() {
        let out = generate_style("Lib", "u", Some("Use camelCase"), "0.1.0");
        assert!(out.contains("# Style Guide — Lib"));
        assert!(out.contains("Use camelCase"));
    }

    #[test]
    fn style_fallback() {
        let out = generate_style("Lib", "u", None, "0.1.0");
        assert!(out.contains("No specific style guidelines"));
    }

    // do_dont.md tests ------------------------------------------------------

    #[test]
    fn do_dont_with_enrichment() {
        let out = generate_do_dont("Lib", "u", Some("DO: validate inputs\nDON'T: use eval"), "0.1.0");
        assert!(out.contains("# Do's and Don'ts — Lib"));
        assert!(out.contains("DO: validate inputs"));
        assert!(out.contains("DON'T: use eval"));
    }

    #[test]
    fn do_dont_fallback() {
        let out = generate_do_dont("Lib", "u", None, "0.1.0");
        assert!(out.contains("No specific do's and don'ts"));
    }

    // Helper tests ----------------------------------------------------------

    #[test]
    fn title_to_anchor_basic() {
        assert_eq!(title_to_anchor("Getting Started"), "getting-started");
        assert_eq!(title_to_anchor("API Reference"), "api-reference");
    }

    #[test]
    fn title_to_anchor_special_chars() {
        assert_eq!(title_to_anchor("What's New?"), "what_s-new_");
    }

    #[test]
    fn sha256_hex_deterministic() {
        let h1 = sha256_hex("hello");
        let h2 = sha256_hex("hello");
        assert_eq!(h1, h2);
        assert_eq!(h1.len(), 64); // 256 bits = 64 hex chars
    }

    #[test]
    fn artifact_names_count() {
        assert_eq!(ARTIFACT_NAMES.len(), 6);
        assert!(ARTIFACT_NAMES.contains(&"llms.txt"));
        assert!(ARTIFACT_NAMES.contains(&"SKILL.md"));
        assert!(ARTIFACT_NAMES.contains(&"do_dont.md"));
    }

    #[test]
    fn artifact_entry_serializes() {
        let entry = ArtifactEntry {
            filename: "llms.txt".into(),
            sha256: "abc123".into(),
            size_bytes: 1024,
        };
        let json = serde_json::to_string(&entry).unwrap();
        assert!(json.contains("\"filename\":\"llms.txt\""));
        assert!(json.contains("\"sha256\":\"abc123\""));
    }
}
